# ğŸ—ï¸ ShadowLearn - Architecture Technique

## Vue d'Ensemble

ShadowLearn est un systÃ¨me d'apprentissage intelligent Ã  5 couches:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. UI Layer (React + Tauri)           â”‚
â”‚     â€¢ ChatWindow, ContextWindow        â”‚
â”‚     â€¢ SuggestionBubble                  â”‚
â”‚     â€¢ LearningDashboard                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. Orchestration Layer                 â”‚
â”‚     â€¢ Process triggers end-to-end       â”‚
â”‚     â€¢ Telemetry collection               â”‚
â”‚     â€¢ Error handling                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Learning Layer (Rust)               â”‚
â”‚     â€¢ Context â†’ Clustering               â”‚
â”‚     â€¢ Intent Detection                   â”‚
â”‚     â€¢ Bandit (Thompson Sampling)         â”‚
â”‚     â€¢ Trust Scoring                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Generation Layer                    â”‚
â”‚     â€¢ LLM Client (Ollama/OpenAI)        â”‚
â”‚     â€¢ Adaptive Prompting                 â”‚
â”‚     â€¢ Artefact Generator                 â”‚
â”‚     â€¢ Validator                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Context Engine                       â”‚
â”‚     â€¢ OS Observation (App Detection)     â”‚
â”‚     â€¢ Clipboard Monitor                  â”‚
â”‚     â€¢ Context Aggregation                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”‘ Composants ClÃ©s

### 1. Context Engine (`src-tauri/src/context/`)

**ResponsabilitÃ©**: Capture le contexte utilisateur

**Modules:**
- `app_detector.rs` - DÃ©tection application active
- `clipboard_monitor.rs` - Monitoring presse-papiers
- `aggregator.rs` - AgrÃ©gation du contexte

**API Principale:**
```rust
pub struct ContextAggregator {
    app_detector: AppDetector,
    clipboard_monitor: ClipboardMonitor,
}

impl ContextAggregator {
    pub async fn capture() -> Result<Context, Error>;
    pub async fn get_recent_contexts() -> Vec<Context>;
}
```

### 2. Learning Layer (`src-tauri/src/learning/`)

**ResponsabilitÃ©**: Traitement intelligent du contexte

**Modules:**
- `clustering/` - Groupement SimHash (LSH)
- `intent/` - DÃ©tection d'intention (LLM)
- `bandit.rs` - Thompson Sampling
- `trust.rs` - Scoring utilisateur
- `anomaly.rs` - DÃ©tection anomalies

**Flow:**
```
Context â†’ Clustering â†’ Intent â†’ Bandit â†’ Trust Weight â†’ Decision
```

### 3. Generation Layer

**Adaptive Prompting** (`src-tauri/src/adaptive/`)
- Prompts contextuels
- Templates adaptatifs
- Cache TTL 10min

**Artefact Generation** (`src-tauri/src/artefact/`)
- Types: Text, Blend, Midi, Shader, Json, Python
- LLM + Fallback
- Validation

### 4. Orchestration (`src-tauri/src/orchestrator.rs`)

**ResponsabilitÃ©**: Workflow end-to-end

**Flow Complet:**
```rust
pub async fn process_trigger() -> Result<SuggestionResponse> {
    // 1. Capture context
    let ctx = capture_context().await?;
    
    // 2. Check trigger decision
    let decision = check_trigger(&ctx).await?;
    
    // 3. Process context (cluster + intent)
    let processed = process_context(&ctx).await?;
    
    // 4. Select artefact (bandit)
    let artefact_type = select_artefact(&processed).await?;
    
    // 5. Generate resource
    let artefact = generate_resource(&processed, &artefact_type).await?;
    
    // 6. Create suggestion
    let suggestion = create_suggestion(&ctx, &artefact).await?;
    
    // 7. Emit to frontend
    emit("suggestion_ready", &suggestion).await;
    
    Ok(SuggestionResponse { suggestion, artefact, context: ctx })
}
```

### 5. UI Layer

**React Components:**
- `ChatWindow.tsx` - Interface principale
- `ContextWindow.tsx` - Affichage contexte
- `SuggestionBubble.tsx` - Bulle de suggestion
- `LearningDashboard.tsx` - Dashboard dev

**Tauri Commands:**
- `generate_artifact()` - GÃ©nÃ©ration
- `record_artifact_feedback()` - Feedback
- `get_health_status()` - Health
- `get_telemetry_stats()` - Stats

---

## ğŸ”„ Flux de DonnÃ©es

### Pipeline Complet

```
1. Context Capture (3-5ms)
   â†“
2. Trigger Decision (50-100ms)
   â†“
3. Clustering (10-50ms)
   â†“
4. Intent Detection (500-2000ms LLM)
   â†“
5. Bandit Selection (1-5ms)
   â†“
6. Artefact Generation (1000-5000ms LLM)
   â†“
7. Validation (50-500ms)
   â†“
8. Storage + UI (10-20ms)
```

**Latence cible p95**: < 10s

### Outcome Recording

```
User Action â†’ Outcome Record â†’ Learning Update
                                    â†“
                            Trust Score Update
                                    â†“
                            Policy Update (Bandit)
```

---

## ğŸ’¾ Base de DonnÃ©es

### Structure SQLite

**Tables Principales:**

```sql
-- Contexts
CREATE TABLE contexts (
    id TEXT PRIMARY KEY,
    app_name TEXT,
    domain TEXT,
    timestamp INTEGER,
    metadata TEXT
);

-- Suggestions
CREATE TABLE suggestions (
    id TEXT PRIMARY KEY,
    context_id TEXT,
    artefact_type TEXT,
    prompt_signature TEXT,
    confidence REAL,
    timestamp INTEGER
);

-- Outcomes
CREATE TABLE outcomes (
    id TEXT PRIMARY KEY,
    suggestion_id TEXT,
    used BOOLEAN,
    helpful BOOLEAN,
    reward REAL,
    timestamp INTEGER
);

-- Clusters
CREATE TABLE clusters (
    id TEXT PRIMARY KEY,
    fingerprint TEXT,
    size INTEGER,
    created_at INTEGER,
    updated_at INTEGER
);
```

### AccÃ¨s

```rust
pub struct DatabaseManager {
    pool: sqlx::SqlitePool,
}

impl DatabaseManager {
    pub async fn store_context(&self, ctx: &Context) -> Result<()>;
    pub async fn get_recent_contexts(&self, limit: usize) -> Vec<Context>;
    pub async fn store_suggestion(&self, sug: &Suggestion) -> Result<()>;
    pub async fn record_outcome(&self, outcome: &Outcome) -> Result<()>;
}
```

---

## ğŸ§ª Tests

### Structure

```
src-tauri/tests/
â”œâ”€â”€ integration/
â”‚   â”œâ”€â”€ context_capture.rs
â”‚   â”œâ”€â”€ trigger_decision.rs
â”‚   â”œâ”€â”€ learning_pipeline.rs
â”‚   â””â”€â”€ full_flow.rs
â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ clustering.rs
â”‚   â”œâ”€â”€ bandit.rs
â”‚   â””â”€â”€ trust.rs
â””â”€â”€ benches/
    â”œâ”€â”€ context_bench.rs
    â””â”€â”€ learning_bench.rs
```

### ExÃ©cution

```bash
# Tests unitaires
cargo test --lib

# Tests d'intÃ©gration
cargo test --test '*'

# Benchmarks
cargo bench
```

---

## ğŸ”§ Configuration

### Variables d'Environnement

```bash
# LLM Provider
export SL_LLM_PROVIDER=ollama     # ou 'openai'
export SL_LLM_MODEL=llama2       # modÃ¨le Ã  utiliser

# Feature Flags
export SL_USE_INTENT_GATE=true    # Validation d'intent
export SL_SMART_TRIGGERS=true     # Triggers intelligents
export SL_TELEMETRY=true          # Collecte mÃ©triques

# Logs
export RUST_LOG=info              # Niveau de log
```

### Configuration Runtime

```rust
pub struct Config {
    pub idle_threshold_ms: u64,      // 12000 (12s)
    pub action_cooldown_ms: u64,     // 45000 (45s)
    pub dismiss_cooldown_ms: u64,    // 90000 (90s)
    pub trust_threshold: f32,        // 0.5
    pub max_clusters: usize,         // 1000
}
```

---

## ğŸš€ DÃ©ploiement

### Build

```bash
# macOS (universal)
cargo tauri build --target universal-apple-darwin

# Windows
cargo tauri build --target x86_64-pc-windows-msvc

# Linux
cargo tauri build --target x86_64-unknown-linux-gnu
```

### Distribution

- **macOS**: `.dmg` installer
- **Windows**: `.msi` installer
- **Linux**: `.AppImage` ou `.deb`

---

## ğŸ“Š MÃ©triques

### Performance

- **Context Capture**: < 50ms
- **Clustering**: < 100ms
- **Intent Detection**: < 2000ms (LLM)
- **Bandit Selection**: < 10ms
- **Full Flow**: < 10s (p95)

### Ressources

- **RAM**: 50-200MB
- **CPU**: 1-5%
- **Stockage**: 10-100MB (selon usage)

### QualitÃ©

- **Trust Score**: 0.0 - 1.0
- **Success Rate**: % suggestions positives
- **Cache Hit Rate**: > 40%

---

## ğŸ” SÃ©curitÃ©

### Permissions

- **Capture d'Ã©cran** - NÃ©cessaire pour contexte visuel
- **AccessibilitÃ©** - Optionnel pour idle detection
- **Fichiers** - Lecture/Ã©criture artefacts

### ConfidentialitÃ©

- âœ… Toutes donnÃ©es locales
- âœ… Pas de tracking
- âœ… LLM optionnel
- âœ… Open source

---

## ğŸ› ï¸ DÃ©veloppement

### Setup

```bash
# Clone
git clone https://github.com/shadowlearn/shadowlearn

# Install dependencies
pnpm install
cd src-tauri
cargo build

# Run dev
pnpm tauri dev
```

### Structure Projet

```
shadowlearn/
â”œâ”€â”€ src/                      # Frontend React
â”‚   â”œâ”€â”€ components/          # Composants UI
â”‚   â”œâ”€â”€ hooks/               # Hooks React
â”‚   â””â”€â”€ styles/              # CSS
â”œâ”€â”€ src-tauri/src/           # Backend Rust
â”‚   â”œâ”€â”€ context/             # Context Engine
â”‚   â”œâ”€â”€ learning/            # Learning Layer
â”‚   â”œâ”€â”€ orchestration/       # Orchestration
â”‚   â”œâ”€â”€ telemetry/           # Telemetry
â”‚   â””â”€â”€ lib.rs               # Point d'entrÃ©e
â”œâ”€â”€ docs/                    # Documentation
â””â”€â”€ tests/                   # Tests
```

---

**Version**: 1.0.0  
**Architecture**: 5-layer intelligent learning system

